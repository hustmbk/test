#!/bin/bash
# CUTLASSå®‰è£…è„šæœ¬ - é’ˆå¯¹H20 GPUä¼˜åŒ–
# ä½œè€…: Claude Code Assistant

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

echo "ğŸš€ å¼€å§‹å®‰è£…CUTLASS for H20 GPU (SM_90a)..."

# æ£€æŸ¥CUDAç‰ˆæœ¬
echo "ğŸ“‹ æ£€æŸ¥CUDAç¯å¢ƒ..."
nvcc --version

# è¿›å…¥libraryç›®å½•
cd /root/autodl-tmp/RetrievalAttention/library

# 1. è§£å‹CUTLASSï¼ˆå‡è®¾ç”¨æˆ·å·²ä¸Šä¼ cutlass-main.zipï¼‰
echo "ğŸ“¦ è§£å‹CUTLASS..."
if [ -f "cutlass-main.zip" ]; then
    unzip -q cutlass-main.zip
    mv cutlass-main cutlass
    echo "âœ… CUTLASSè§£å‹å®Œæˆ"
else
    echo "âŒ æœªæ‰¾åˆ°cutlass-main.zipï¼Œè¯·ç¡®ä¿å·²ä¸Šä¼ è¯¥æ–‡ä»¶"
    exit 1
fi

# 2. å®‰è£…CUDA BLAS for H20 GPU
echo "ğŸ”§ å®‰è£…H20 GPUä¸“ç”¨CUDA BLAS..."
pip install nvidia-cublas-cu12==12.4.5.8

# 3. åˆ›å»ºCUTLASSæ„å»ºç›®å½•
echo "ğŸ—ï¸ å‡†å¤‡æ„å»ºCUTLASS..."
cd cutlass
mkdir -p build
cd build

# 4. é…ç½®CMake for H20 GPU (SM_90a)
echo "âš™ï¸ é…ç½®CMake for H20 GPU (SM_90a)..."
cmake .. \
    -DCUTLASS_NVCC_ARCHS=90a \
    -DCUTLASS_LIBRARY_KERNELS=all \
    -DCUTLASS_ENABLE_CUBLAS=ON \
    -DCUTLASS_ENABLE_CUDNN=OFF \
    -DUBSAN=OFF \
    -DCMAKE_BUILD_TYPE=Release

# 5. ç¼–è¯‘CUTLASS
echo "ğŸ”¨ ç¼–è¯‘CUTLASSåº“..."
make -j$(nproc)

# 6. å®‰è£…CUTLASS
echo "ğŸ“¥ å®‰è£…CUTLASS..."
make install

# 7. è¿”å›libraryç›®å½•å‡†å¤‡å®‰è£…RetroInfer kernels
cd /root/autodl-tmp/RetrievalAttention/library

# 8. ä¿®æ”¹RetroInfer setup.pyä»¥æ”¯æŒH20 GPU
echo "ğŸ”§ é…ç½®RetroInfer for H20 GPU..."
cd retroinfer

# å¤‡ä»½åŸå§‹setup.py
cp setup.py setup.py.backup

# ä¿®æ”¹setup.pyæ”¯æŒSM_90a
cat > setup.py << 'EOF'
import os
from setuptools import setup, Extension
from pybind11.setup_helpers import Pybind11Extension, build_ext

# CUDAå’ŒCUTLASSè·¯å¾„
cuda_home = os.environ.get('CUDA_HOME', '/usr/local/cuda')
cutlass_path = '../cutlass'

# H20 GPU (SM_90a) ä¼˜åŒ–ç¼–è¯‘å‚æ•°
compile_args = [
    '-O3',
    '-std=c++17',
    '-DWITH_CUDA',
    '-DCUTLASS_ENABLE_TENSOR_CORE_MMA=1',
    f'-I{cuda_home}/include',
    f'-I{cutlass_path}/include',
    f'-I{cutlass_path}/tools/util/include',
    f'-I{cutlass_path}/examples/common',
    '--expt-extended-lambda',
    '--expt-relaxed-constexpr',
    '-Xcompiler=-fPIC',
    '-Xcompiler=-Wno-float-conversion',
    '-gencode=arch=compute_90a,code=sm_90a',  # H20 GPUä¸“ç”¨
    '-DCUTLASS_ARCH_MMA_SM90A_SUPPORTED=1'
]

link_args = [
    f'-L{cuda_home}/lib64',
    '-lcudart',
    '-lcublas',
    '-lcurand'
]

# æºæ–‡ä»¶
sources = [
    'retroinfer_kernels.cpp',
    # æ·»åŠ å…¶ä»–å¿…è¦çš„æºæ–‡ä»¶
]

ext_modules = [
    Pybind11Extension(
        'retroinfer_kernels',
        sources,
        extra_compile_args=compile_args,
        extra_link_args=link_args,
        language='c++'
    )
]

setup(
    name='retroinfer_kernels',
    ext_modules=ext_modules,
    cmdclass={'build_ext': build_ext},
    python_requires='>=3.8',
)
EOF

echo "âœ… RetroInfer setup.pyå·²é…ç½®ä¸ºæ”¯æŒH20 GPU"

# 9. ç¼–è¯‘å¹¶å®‰è£…RetroInfer kernels
echo "ğŸ”¨ ç¼–è¯‘RetroInfer kernels..."
pip install . -v

# 10. éªŒè¯å®‰è£…
echo "ğŸ§ª éªŒè¯å®‰è£…..."
cd /root/autodl-tmp/RetrievalAttention
python -c "
try:
    import retroinfer_kernels
    print('âœ… RetroInfer kernelså¯¼å…¥æˆåŠŸ')
    
    # æµ‹è¯•CUDAè®¾å¤‡
    import torch
    if torch.cuda.is_available():
        device = torch.cuda.get_device_properties(0)
        print(f'âœ… CUDAè®¾å¤‡: {device.name}')
        print(f'âœ… è®¡ç®—èƒ½åŠ›: {device.major}.{device.minor}')
    else:
        print('âŒ CUDAä¸å¯ç”¨')
        
except ImportError as e:
    print(f'âŒ RetroInfer kernelså¯¼å…¥å¤±è´¥: {e}')
except Exception as e:
    print(f'âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}')
"

echo "ğŸ‰ CUTLASSå’ŒRetroInferå®‰è£…å®Œæˆï¼"
echo "ğŸ“ ç°åœ¨å¯ä»¥è¿è¡Œæµ‹è¯•: python -u simple_test.py --batch_size 4"